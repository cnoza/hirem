---
title: "Testing the hierarchical reserving models on the simulation engine proposed by Wang and Wuthrich"
author: "Christophe Nozaradan"
date: "October 2022"
output: html_document
bibliography: references.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
options(dplyr.summarise.inform = FALSE)
```

## Introduction
This document implements hierarchical reserving models based on the extended hirem package. The input data is generated using the simulation engine from Wang and Wuthrich, described the following paper:

Wang, Melantha and Wuthrich, Mario V., Individual Claims Generator for Claims Reserving Studies: Data Simulation.R (June 3, 2022). Available at SSRN: https://ssrn.com/abstract=4127073 or http://dx.doi.org/10.2139/ssrn.4127073

## Simulating the portfolio
We evaluate the predictive performance of our hierarchical reserving model (hierarchical GLM, hierarchical GBM, hierarchical XGB and hierarchical DNN) on one portfolio simulated along the extreme event scenario. We compare the results with the ones obtained using an aggregate reserving model, namely the classical chain ladder model.

First, we load the required packages.

```{r, results='hide'}
require(SynthETIC)  # 1.0.0 or higher needed
require(plyr)
require(dplyr)
require(locfit)
require(actuar)
require(tidyr)
require(lubridate)
require(tidyverse)
require(xgboost)
require(Matrix)
require(tidyverse)
require(data.table)
require(ggplot2)
require(recipes)
require(tensorflow)
require(keras)
#install.packages('devtools')
#devtools::install_github('cnoza/hirem')
require(hirem)

```

We simulate one portfolio using the simulation engine from Wang and Wuthrich.


```{r}
ref_claim <- 1          # currency is 1
time_unit <- 1/12       # we consider monthly claims development
set_parameters(ref_claim=ref_claim, time_unit=time_unit)

years <- 17               # number of occurrence years
I <- years/time_unit      # number of development periods

source("./wang-wuthrich/Tools/functions simulation.R")
dest_path <- "" # plot to be saved in ...

#####################################################################
#### generate claim data
#####################################################################

# generate individual claims: may take 60 seconds
claims_list <- data.generation(seed=1000, future_info=F)

# save individual output for easier access
claims <- claims_list[[1]]
claims <- claims %>% filter(Status == 'Closed')

paid <- claims_list[[2]] %>% filter(Paid > 0)

# For comparison purposes
reserving_data_h <- simulate_scenario_extreme_event(seed = 1, period_extra = '2019', n = 125000)

# We now build a reserving dataset compatible with hirem

d0 <- merge(paid, claims, by="Id") %>%
  arrange(Id, EventId)

d0 <- d0 %>% 
  mutate(calendar.year = floor(EventMonth/12)+1,
         rep.year = floor(RepMonth/12)+1,
         dev.year = calendar.year - rep.year + 1,
         size = Paid) %>%
  select(Id, dev.year, size)

d1 <- expand.grid(Id = unique(d0$Id),
                  dev.year = 1:max(d0$dev.year),
                  size = 0)

d2 <- union_all(d0,d1)

d3 <- d2 %>% 
    group_by(Id, dev.year) %>%
    dplyr::summarise(total = sum(size))
colnames(d3) <- c('Id','dev.year', 'size')

d4 <- merge(d3, claims, by="Id", all.x = T)

reserving_data <- d4 %>% 
  mutate(rep.year = floor(RepMonth/12)+1,
         calendar.year = dev.year + rep.year - 1,
         settlement.year = floor(SetMonth/12)+1,
         payment = as.integer(size>0),
         occ.month = AccMonth,
         occ.date = AccDate,
         occ.weekday = factor(AccWeekday),
         rep.date = RepDate,
         age = Age,
         settlement = as.integer(calendar.year >= settlement.year),
         open = as.integer(ifelse(calendar.year==settlement.year,1,1-settlement)),
         type = factor(Type),
         rep.month = factor(month(ymd(RepDate)))) %>%
  select(-CumPaid, -Ultimate, -Type, -Status, -PayCount, -AccMonth, -AccDate, -Age, -AccWeekday, -RepDate, RepMonth) %>%
  arrange(Id, dev.year)

reserving_data <- reserving_data %>% filter(rep.year <= 10 & dev.year <= 10)

reserving_data$dev.year.fact <- factor(reserving_data$dev.year, levels = 1:max(reserving_data$dev.year))
reserving_data$rep.year.fact <- factor(reserving_data$rep.year, levels = 1:max(reserving_data$rep.year))

reserving_data$monthDev12 <- as.character(reserving_data$rep.month)
reserving_data$monthDev12[reserving_data$dev.year > 3] <- 'dev.year > 3'
reserving_data$devYearMonth <- factor(paste(reserving_data$dev.year, reserving_data$monthDev12, sep = '-'))

# We remove recoveries for the moment
reserving_data <- as_tibble(reserving_data %>% filter(size >= 0))

str(reserving_data)

```
 
Next, we set the evaluation date to .... The observed portfolio then consists of the claims that are reported before this evaluation date, i.e. with calendar year before year 9.  The prediction data set consists of the remaining claims, namely the claims reported after calendar year 9.

```{r}
# Observed and prediction data set
observed_data   <- reserving_data %>% filter(calendar.year <= 10)
prediction_data <- reserving_data %>% filter(calendar.year > 10)

# For comparison purposes
observed_data_h   <- reserving_data_h %>% filter(calendar.year <= 9)
prediction_data_h <- reserving_data_h %>% filter(calendar.year > 9)
```

## Calibration of the hierarhical reserving models
We first define the weights used in the calibration of the hierarchical reserving model. The purpose of these weights is to replicate the development year distribution from the prediction data set to the observed data set (training data set). Hence, more weight is assigned to claims observations in later development years since reporting. We give a very small weight to the claims observations in the first development year since reporting because the prediction data set does not contain observations for this development year. More details are provided in @hirempaper

```{r}
# Calculating the weights
reported_claims <- observed_data %>%
  dplyr::filter(dev.year == 1) %>%
  group_by(rep.year) %>% 
  dplyr::summarise(count = n()) %>%
  pull(count)

denominator <- tail(rev(cumsum(reported_claims)), -1)
numerator <- head(cumsum(rev(reported_claims)), -1)
weight <- c(10^(-6), numerator / denominator)

names(weight) <- paste0('dev.year',1:10)
weight
```

### Hierarchical GLM

The hierarchical GLM consists of the three layer structure: settlement, payment and size. We model the settlement indicator using a binomial regression model with a complementary log link function. The payment indicator will be modeled using a logistic regression model and the payment sizes using a Gamma GLM with log-link function. 

We define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`).

```{r}
# Model specifications hierarchical GLM
model_glm  <- hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 10, open == 1)) %>%
  layer_glm(name = 'settlement', 'family' = binomial(link = cloglog)) %>%
  layer_glm(name = 'payment', 'family' = binomial(link = logit)) %>%
  layer_glm(name = 'size', 'family' = Gamma(link = 'log'), 
            filter = function(x){x$payment == 1})
```

Next, we perform a covariate selection procedure to select the optimal covariates that are retained in the regression models for each layer. Here, we just list the formulae with the retained covariates, but the details of this covariate selection are provided in @hirempaper.

```{r}
# Formulae hierarchical GLM layers - model calibration
formula_settle_glm <- "settlement ~ type + dev.year.fact"
formula_pay_glm    <- "payment ~ settlement + type + devYearMonth"
formula_size_glm   <- "size ~ devYearMonth + type + settlement + rep.month"
```

We fit the hierarchical GLM on the observed portfolio of simulated claims.

```{r}
# Fitting the hierarchical GLM
model_glm <- hirem::fit(model_glm,
                 weights = weight,
                 weight.var = 'dev.year',
                 balance.var = 'dev.year',
                 settlement = formula_settle_glm,
                 payment = formula_pay_glm,
                 size = formula_size_glm)
```

### Hierarchical GBM

The hierarchical GBM consists of the same three layer structure and the same distributional assumptions as the hierarchical GLM. However each layer is now modeled with a GBM instead of a GLM.

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`). We tune some of the GBM parameters (number of trees, interaction depth and shrinkage) using a 5-fold cross validation approach [@hirempaper]. We list here the obtained results from the tuning strategy in the paper. We further fix the `bag.fraction` to 0.75 and the minimum number of observecations each node (`n.minobsinnode`) to 100.

```{r}
# Results of hierarchical model calibration
gbm_param_settle <- list('n.trees' = 225, 'interaction.depth' = 1, 'shrinkage' = 0.05)
gbm_param_pay    <- list('n.trees' = 125, 'interaction.depth' = 3, 'shrinkage' = 0.05)
gbm_param_size   <- list('n.trees' = 700, 'interaction.depth' = 1, 'shrinkage' = 0.05)

# Model specifications
model_gbm <- hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 10, open == 1)) %>%
  layer_gbm('settlement', distribution = 'bernoulli', bag.fraction = 0.75, n.minobsinnode = 100,
            n.trees = gbm_param_settle$n.trees, interaction.depth = gbm_param_settle$interaction.depth,
            shrinkage = gbm_param_settle$shrinkage, select_trees = 'last') %>%
  layer_gbm('payment', distribution = 'bernoulli', bag.fraction = 0.75, n.minobsinnode = 100,            
            n.trees = gbm_param_pay$n.trees, interaction.depth = gbm_param_pay$interaction.depth,
            shrinkage = gbm_param_pay$shrinkage, select_trees = 'last') %>%
  layer_gbm('size', distribution = 'gamma', bag.fraction = 0.75, n.minobsinnode = 100,
            n.trees = gbm_param_size$n.trees, interaction.depth = gbm_param_size$interaction.depth,
            shrinkage = gbm_param_size$shrinkage, select_trees = 'last',
            filter = function(data){data$payment == 1})
```

We now fit the hierarchical GBM on the observed portfolio of simulated claims.

```{r}
# Covariates
covariates_gbm <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'age', 'calendar.year')

# Fitting the hierarchical GBM
model_gbm <- hirem::fit(model_gbm,
                 weights = weight,
                 weight.var = 'dev.year',
                 balance.var = 'dev.year',
                 settlement = paste0('settlement ~ 1 + ', paste0(covariates_gbm, collapse = ' + ')),
                 payment = paste0('payment ~ 1 + ', paste0(c(covariates_gbm, 'settlement'), collapse = ' + ')),
                 size = paste0('size ~ 1 + ', paste0(c(covariates_gbm,'settlement'), collapse = ' + ')))
```

### Hierarchical XGB

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`).

To tune the hyperparameters, one can activate a cross-validation by setting the `nfolds` parameter to the desired integer in the `layer_xgb` function. Optionally, one can provide a `hyper_grid` parameter or use a predefined one. The hyperparameters performing the best will then be retained automatically.

```{r message=TRUE}
# Results of hierarchical model calibration
xgb_param_settle <- list('eta' =   1, 'max_depth' = 1, 'nrounds' =  10, 'subsample' = 1)
xgb_param_pay    <- list('eta' =  .5, 'max_depth' = 3, 'nrounds' =  10, 'subsample' = 1)
xgb_param_size   <- list('eta' = .05, 'max_depth' = 1, 'nrounds' = 690, 'subsample' = .75)

# Model specifications
model_xgb <- hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 10, open == 1)) %>%
  layer_xgb('settlement', objective = 'binary:logistic', eval_metric = 'logloss', grow_policy = 'lossguide',
            eta = xgb_param_settle$eta, max_depth = xgb_param_settle$max_depth, 
            nrounds = xgb_param_settle$nrounds, subsample = xgb_param_settle$subsample) %>%
  layer_xgb('payment', objective = 'binary:logistic', eval_metric = 'logloss', grow_policy = 'lossguide',
            eta = xgb_param_pay$eta, max_depth = xgb_param_pay$max_depth, 
            nrounds = xgb_param_pay$nrounds, subsample = xgb_param_pay$subsample) %>%
  layer_xgb('size', objective = 'reg:gamma', 
            eval_metric = 'gamma-deviance', grow_policy = 'lossguide',
            eta = xgb_param_size$eta, max_depth = xgb_param_size$max_depth, 
            nrounds = xgb_param_size$nrounds, subsample = xgb_param_size$subsample,
            filter = function(data){data$payment == 1})
```

We now fit the hierarchical XGB on the observed portfolio of simulated claims.

```{r}
# Covariates
covariates_xgb <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'age', 'calendar.year')

# Fitting the hierarchical XGB
model_xgb <- hirem::fit(model_xgb,
                        weights = weight,
                        weight.var = 'dev.year',
                        balance.var = 'dev.year',
                        settlement = paste0('settlement ~ ', paste0(covariates_xgb, collapse = ' + ')),
                        payment = paste0('payment ~ ', paste0(c(covariates_xgb, 'settlement'), collapse = ' + ')),
                        size = paste0('size ~ ', paste0(c(covariates_xgb,'settlement'), collapse = ' + ')))
```
We can obtain the cross-validation results as follows:
```{r}
if(!is.null(model_xgb$layers$settlement$hyper_grid)) model_xgb$layers$settlement$hyper_grid
if(!is.null(model_xgb$layers$payment$hyper_grid)) model_xgb$layers$payment$hyper_grid
if(!is.null(model_xgb$layers$size$hyper_grid)) model_xgb$layers$size$hyper_grid
```

```{r}
# Variable importance
xgb.importance(colnames(model_xgb$layers$settlement$fit), model = model_xgb$layers$settlement$fit)

```

```{r}
# Variable importance
xgb.importance(colnames(model_xgb$layers$payment$fit), model = model_xgb$layers$payment$fit)

```

```{r}
# Variable importance
xgb.importance(colnames(model_xgb$layers$size$fit), model = model_xgb$layers$size$fit)

```

### Hierarchical DNN

We will use the gamma deviance as custom loss function and metric in `keras`:

```{r, message=FALSE}
gamma_deviance_keras <- function(yobs, yhat) {
  K <- backend()
  2*K$mean((yobs-yhat)/yhat - K$log(yobs/yhat))
}

metric_gamma_deviance_keras <- keras::custom_metric("gamma_deviance_keras", function(yobs, yhat) {
  gamma_deviance_keras(yobs, yhat)
})
```

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 10`). 

```{r message=FALSE, warning=FALSE}

# Model specifications
model_dnn <-  hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 10, open == 1)) %>%
  layer_dnn('settlement', distribution = 'bernoulli',
            bias_regularization = T, 
            hidden = c(40,30,40),
            loss = 'binary_crossentropy',
            metrics = 'binary_crossentropy',
            optimizer = optimizer_nadam(),
            validation_split = .3,
            activation.output = 'sigmoid',
            family_for_init = binomial(), # default link = logit
            epochs = 100,
            batch_size = 1000,
            monitor = 'val_binary_crossentropy',
            patience = 20) %>%
  layer_dnn('payment', distribution = 'bernoulli',
            bias_regularization = T,
            hidden = c(30,40,20),
            loss = 'binary_crossentropy',
            metrics = 'binary_crossentropy',
            optimizer = optimizer_nadam(),
            validation_split = .3,
            activation.output = 'sigmoid',
            family_for_init = binomial(), # default link = logit
            epochs = 100,
            batch_size = 1000,
            monitor = 'val_binary_crossentropy',
            patience = 20) %>%
  layer_dnn('size', distribution = 'gamma',
            bias_regularization = T, 
            hidden = c(50,40,60),
            loss = gamma_deviance_keras,
            metrics = metric_gamma_deviance_keras,
            optimizer = optimizer_nadam(),
            validation_split = .3,
            activation.output = 'exponential',
            family_for_init = Gamma(link=log), # default link = inverse
            epochs = 100,
            batch_size = 1000,
            monitor = 'val_gamma_deviance_keras',
            patience = 20,
            filter = function(data){data$payment == 1})
```
We now fit the hierarchical DNN on the observed portfolio of simulated claims.

```{r message=FALSE, warning=FALSE}
# Covariates
covariates_dnn <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'calendar.year')

# Fitting the hierarchical MLP
model_dnn <- hirem::fit(model_dnn,
                        balance.var = 'dev.year',
                        settlement = paste0('settlement ~ ', paste0(covariates_dnn, collapse = ' + ')),
                        payment = paste0('payment ~ ', paste0(c(covariates_dnn, 'settlement'), collapse = ' + ')),
                        size = paste0('size ~ ', paste0(c(covariates_dnn,'settlement'), collapse = ' + ')))
```

We can obtain the cross-validation results as follows:
```{r}
if(!is.null(model_dnn$layers$settlement$hyper_grid)) model_dnn$layers$settlement$hyper_grid
if(!is.null(model_dnn$layers$payment$hyper_grid)) model_dnn$layers$payment$hyper_grid
if(!is.null(model_dnn$layers$size$hyper_grid)) model_dnn$layers$size$hyper_grid
```

We show the model retained:
```{r}
if(!is.null(model_dnn$layers$settlement$fit.biased)) model_dnn$layers$settlement$fit.biased
if(!is.null(model_dnn$layers$payment$fit.biased)) model_dnn$layers$payment$fit.biased
if(!is.null(model_dnn$layers$size$fit.biased)) model_dnn$layers$size$fit.biased
```

### Hierarchical CANN

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 10`).

```{r message=FALSE, warning=FALSE}
# Model specifications
model_cann <-  hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 10, open == 1)) %>%
  layer_cann('settlement', distribution = 'bernoulli',
             hidden = c(50,50,50),
             formula.glm = formula_settle_glm, 
             bias_regularization = T,
             family_for_glm = binomial(),
             loss = 'binary_crossentropy',
             metrics = 'binary_crossentropy',
             optimizer = optimizer_nadam(),
             validation_split = .3,
             activation.output = 'linear',
             activation.output.cann = 'sigmoid',
             fixed.cann = T,
             monitor = 'val_binary_crossentropy',
             patience = 20,
             epochs = 100,
             batch_size = 1000) %>%
  layer_cann('payment', distribution = 'bernoulli',
             hidden = c(30,30,50),
             formula.glm = formula_pay_glm, 
             bias_regularization = T,
             family_for_glm = binomial(),
             loss = 'binary_crossentropy',
             metrics = 'binary_crossentropy',
             optimizer = optimizer_nadam(),
             validation_split = .3,
             activation.output = 'linear',
             activation.output.cann = 'sigmoid',
             fixed.cann = T,
             monitor = 'val_binary_crossentropy',
             patience = 20,
             epochs = 100,
             batch_size = 1000) %>%
  layer_cann('size', distribution = 'gamma',
             hidden = c(40,20,20),
             formula.glm = formula_size_glm, 
             bias_regularization = T,
             family_for_glm = Gamma(link=log),
             loss = gamma_deviance_keras,
             metrics = metric_gamma_deviance_keras,
             optimizer = optimizer_nadam(),
             validation_split = .3,
             activation.output = 'linear',
             activation.output.cann = 'exponential',
             fixed.cann = T,
             monitor = 'val_gamma_deviance_keras',
             patience = 20,
             epochs = 100, 
             batch_size = 1000,
             filter = function(data){data$payment == 1})
```

We now fit the hierarchical CANN on the observed portfolio of simulated claims. Notice that `dev.year.fact` is removed from the list of covariates to prevent an issue in the calibration process (loss function is `nan`).

```{r}
#Covariates
covariates_cann <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'calendar.year')

# Fitting the hierarchical CANN
model_cann <- hirem::fit(model_cann,
                 balance.var = 'dev.year',
                 settlement = paste0('settlement ~ ', paste0(covariates_cann, collapse = ' + ')),
                 payment = paste0('payment ~ ', paste0(c(covariates_cann, 'settlement'), collapse = ' + ')),
                 size = paste0('size ~ ', paste0(c(covariates_cann,'settlement'), collapse = ' + ')))
```
We can obtain the cross-validation results (hypergrid case) as follows:
```{r}
if(!is.null(model_cann$layers$settlement$hyper_grid)) model_cann$layers$settlement$hyper_grid
if(!is.null(model_cann$layers$payment$hyper_grid)) model_cann$layers$payment$hyper_grid
if(!is.null(model_cann$layers$size$hyper_grid)) model_cann$layers$size$hyper_grid
```

We show the model retained:
```{r}
if(!is.null(model_cann$layers$settlement$fit.biased)) model_cann$layers$settlement$fit.biased
if(!is.null(model_cann$layers$payment$fit.biased)) model_cann$layers$payment$fit.biased
if(!is.null(model_cann$layers$size$fit.biased)) model_cann$layers$size$fit.biased
```


## Predicting the future development of claims in the hierarchical reserving models
In the next step, we predict the future development of claims. We do this by simulating 50 different paths for each open claim in the year of the evaluation date and by averaging the results afterwards. In this prediction strategy, the hierarchical structure of the reserving model is preserved and the development of claims are simulated in chronological order.

We define an update function applied to the data for the simulation of each subsequent development year. 

```{r}
# Update function
update <- function(data) {
  data$dev.year <- data$dev.year + 1
  data$dev.year.fact <- factor(data$dev.year, levels = 1:max(reserving_data$dev.year))
  data$calendar.year <- data$calendar.year + 1
  data
}

model_glm <- register_updater(model_glm, update)
model_gbm <- register_updater(model_gbm, update)
model_xgb <- register_updater(model_xgb, update)
model_dnn <- register_updater(model_dnn, update)
model_cann <- register_updater(model_cann, update)
```

Next, we apply the actual simulation of the development of claims over time beyond the observation window of those claims that are still open at the evaluation date (calendar year 11). Moreover, we apply the balance correction as explained in @hirempaper.

```{r}
nsim <- 50 # Instead of 100 (original value), to avoid memory issues

simul_glm <- simulate(model_glm,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 10, settlement == 0)},
                      data = model_glm$data_observed %>% dplyr::filter(calendar.year == 10),
                      balance.correction = TRUE)

simul_gbm <- simulate(model_gbm,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 10, settlement == 0)},
                      data = model_gbm$data_observed %>% dplyr::filter(calendar.year == 10),
                      balance.correction = TRUE)

simul_xgb <- simulate(model_xgb,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 10, settlement == 0)},
                      data = model_xgb$data_observed %>% dplyr::filter(calendar.year == 10),
                      balance.correction = TRUE)

simul_dnn <- simulate(model_dnn,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 10, settlement == 0)},
                      data = model_dnn$data_observed %>% dplyr::filter(calendar.year == 10),
                      balance.correction = TRUE)

simul_cann <- simulate(model_cann,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 10, settlement == 0)},
                      data = model_cann$data_observed %>% dplyr::filter(calendar.year == 10),
                      balance.correction = TRUE)

```

## Chain-ladder model
For comparison, we apply the classical chain ladder model to predict the total number of open claims, the total number of payments and the total payment sizes outside the observation window.

We first construct the incremental run-off triangles for the number of open claims, the number of payments and the total payment sizes in each reporting year and development year since reporting in the observed portfolio. We know the number of open claims in the year following the evaluation date since we have information whether or not a claim settles in the year of settlement. 

```{r}
# Incremental run-off triangles
triangle_open    <- construct_triangle(data = observed_data %>% filter(open == 1), group.var1 = 'rep.year', 
                                       group.var2 = 'dev.year', value = 'open', cumulative = FALSE)
triangle_payment <- construct_triangle(data = observed_data, group.var1 = 'rep.year',
                                       group.var2 = 'dev.year', value = 'payment', cumulative = FALSE)
triangle_size    <- construct_triangle(data = observed_data, group.var1 = 'rep.year',
                                       group.var2 = 'dev.year', value = 'size', cumulative = FALSE)

# Number of open claims in the year following the evaluation date
settle.evalyear <- observed_data %>% 
  filter(open == 1, calendar.year == 10) %>%
  group_by(rep.year, dev.year) %>%
  summarise(settlement = sum(settlement))

# The number of open claims in the year after the evaluation date
triangle_open[row(triangle_open) + col(triangle_open) == 12] <- 
  (triangle_open[row(triangle_open) + col(triangle_open) == 11] - rev(settle.evalyear$settlement))[1:9]
```

We then apply (a special version of) the chain-ladder model on the incremental run-off triangle for the number of open claims. For the number of payments and the payment sizes, we use the classical chain ladder model applied on the cumulative run-off triangles.

```{r}
# Chain ladder predictions
cl_open <- chainLadder_open(triangle_open)
cl_pay  <- chainLadder(triangle_payment, is_cumulatif = FALSE)
cl_size <- chainLadder(triangle_size, is_cumulatif = FALSE)
```

## Evaluating the predictive performance of the chain-ladder model and the hierarchical GLM and GBM

First, we compare the prediction for the total number of open claims in the test set.

```{r}
nsim <- 50

# Predictions
obs_open_total <- prediction_data %>% filter(calendar.year != 11) %>% summarise(Total = sum(open)) %>% pull(Total)
cl_open_total  <- sum(cl_open)
glm_open_total <- simul_glm %>% filter(calendar.year != 11) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
gbm_open_total <- simul_gbm %>% filter(calendar.year != 11) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
xgb_open_total <- simul_xgb %>% filter(calendar.year != 11) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
dnn_open_total <- simul_dnn %>% filter(calendar.year != 11) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
cann_open_total <- simul_cann %>% filter(calendar.year != 11) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)

# Print Results
c('Actual' =  obs_open_total, 'Chain-Ladder' = cl_open_total, 'Hierarchical GLM' = glm_open_total, 'Hierarchical GBM' = gbm_open_total, 'Hierarchical XGB' = xgb_open_total, 'Hierarchical DNN' = dnn_open_total, 'Hierarchical CANN' = cann_open_total)
```

Second, we compare the prediction for the total number of payments in the prediction data set.

```{r}
# Predictions
obs_pay_total <- prediction_data %>% summarise(Total = sum(payment)) %>% pull(Total)
cl_pay_total  <- sum(cl_pay)
glm_pay_total <- simul_glm %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
gbm_pay_total <- simul_gbm %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
xgb_pay_total <- simul_xgb %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
dnn_pay_total <- simul_dnn %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
cann_pay_total <- simul_cann %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)

# Print Results
c('Actual' = obs_pay_total, 'Chain-Ladder' = cl_pay_total, 'Hierarchical GLM' = glm_pay_total, 'Hierarchical GBM' = gbm_pay_total, 'Hierarchical XGB' = xgb_pay_total, 'Hierarchical DNN' = dnn_pay_total, 'Hierarchical CANN' = cann_pay_total)
```

Third, we compare the prediction for the total number of payment sizes in the prediction set.

```{r}
# Predictions
obs_size_total <- prediction_data %>% summarise(Total = sum(size)) %>% pull(Total)
cl_size_total  <- sum(cl_size)
glm_size_total <- simul_glm %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
gbm_size_total <- simul_gbm %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
xgb_size_total <- simul_xgb %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
dnn_size_total <- simul_dnn %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
cann_size_total <- simul_cann %>% summarise(Total = sum(size)/nsim) %>% pull(Total)

# Print Results
c('Actual' = obs_size_total, 'Chain-Ladder' = cl_size_total, 'Hierarchical GLM' = glm_size_total, 'Hierarchical GBM' = gbm_size_total, 'Hierarchical XGB' = xgb_size_total, 'Hierarchical DNN' = dnn_size_total, 'Hierarchical CANN' = cann_size_total)
```

## References

<div id="refs"></div>
