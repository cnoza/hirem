---
title: "Testing the hierarchical reserving models on a simulated portfolio (baseline scenario)"
author: "Christophe Nozaradan (extention of a previous version by Jens Robben)"
date: "November 2021"
output: html_document
bibliography: references.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
options(dplyr.summarise.inform = FALSE)
```

## Introduction
This version of this document extends a previous one written by Jens Robben, in which hierarchical GLM and hierarchical GBM are compared in the case of an extreme scenario. In the present version, hierarchical XGB, hierarchical MLP and hierarchical CANN are further considered in the case of a baseline event scenario. 

## Simulating the portfolio
We evaluate the predictive performance of our hierarchical reserving model (hierarchical GLM, hierarchical GBM, hierarchical XGB and hierarchical MLP) on one portfolio simulated along the extreme event scenario. We compare the results with the ones obtained using an aggregate reserving model, namely the classical chain ladder model.

First, we load the required packages.

```{r, results='hide'}
require(tidyverse)
require(xgboost)
library(ParBayesianOptimization)
library(doParallel)
require(Matrix)
require(data.table)
require(ggplot2)
require(keras)
require(tensorflow)
require(recipes)
#install.packages('devtools')
#devtools::install_github('cnoza/hirem')
require(hirem)
```

We simulate one portfolio (with `set.seed = 1`) along the baseline event scenario. The portfolio initially consists of $125\ 000$ claims, but only the claims that are reported between January 1, 2012 and December 31, 2020 are retained. Claims are tracked over 9 development years since reporting. In addition, we create an extra covariate `devYearMonth`, representing a simplified version of the interaction effect between `dev.year` and `rep.month`.

```{r}
# The complete portfolio
reserving_data <- simulate_scenario_baseline(seed = 1, n = 125000)

# Creating the interaction effect
reserving_data$monthDev12 <- as.character(reserving_data$rep.month)
reserving_data$monthDev12[reserving_data$dev.year > 3] <- 'dev.year > 3'
reserving_data$devYearMonth <- factor(paste(reserving_data$dev.year, reserving_data$monthDev12, sep = '-'))

# Dimension portfolio
dim(reserving_data)
```
 
Next, we set the evaluation date to December 31, 2020. The observed portfolio then consists of the claims that are reported before this evaluation date, i.e. with calendar year before year 9.  The prediction data set consists of the remaining claims, namely the claims reported after calendar year 9.

```{r}
# Observed and prediction data set
observed_data   <- reserving_data %>% filter(calendar.year <= 9)
prediction_data <- reserving_data %>% filter(calendar.year > 9)
```

## Calibration of the hierarhical reserving models
We first define the weights used in the calibration of the hierarchical reserving model. The purpose of these weights is to replicate the development year distribution from the prediction data set to the observed data set (training data set). Hence, more weight is assigned to claims observations in later development years since reporting. We give a very small weight to the claims observations in the first development year since reporting because the prediction data set does not contain observations for this development year. More details are provided in @hirempaper

```{r}
# Calculating the weights
reported_claims <- observed_data %>%
  dplyr::filter(dev.year == 1) %>%
  group_by(rep.year) %>% 
  dplyr::summarise(count = n()) %>%
  pull(count)

denominator <- tail(rev(cumsum(reported_claims)), -1)
numerator <- head(cumsum(rev(reported_claims)), -1)
weight <- c(10^(-6), numerator / denominator)

names(weight) <- paste0('dev.year',1:9)
weight
```

### Hierarchical GLM

The hierarchical GLM consists of the three layer structure: settlement, payment and size. We model the settlement indicator using a binomial regression model with a complementary log link function. The payment indicator will be modeled using a logistic regression model and the payment sizes using a Gamma GLM with log-link function. 

We define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`).

```{r}
# Model specifications hierarchical GLM
model_glm  <- hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 9, open == 1)) %>%
  layer_glm(name = 'settlement', 'family' = binomial(link = cloglog)) %>%
  layer_glm(name = 'payment', 'family' = binomial(link = logit)) %>%
  layer_glm(name = 'size', 'family' = Gamma(link = 'log'), 
            filter = function(x){x$payment == 1})
```

Next, we perform a covariate selection procedure to select the optimal covariates that are retained in the regression models for each layer. Here, we just list the formulae with the retained covariates, but the details of this covariate selection are provided in @hirempaper.

```{r}
# Formulae hierarchical GLM layers - model calibration
formula_settle_glm <- "settlement ~ type + dev.year.fact"
formula_pay_glm    <- "payment ~ settlement + type + devYearMonth"
formula_size_glm   <- "size ~ devYearMonth + type + settlement + rep.month"
```

We fit the hierarchical GLM on the observed portfolio of simulated claims.

```{r}
# Fitting the hierarchical GLM
model_glm <- hirem::fit(model_glm,
                 weights = weight,
                 weight.var = 'dev.year',
                 balance.var = 'dev.year',
                 settlement = formula_settle_glm,
                 payment = formula_pay_glm,
                 size = formula_size_glm)
```

### Hierarchical GBM

The hierarchical GBM consists of the same three layer structure and the same distributional assumptions as the hierarchical GLM. However each layer is now modeled with a GBM instead of a GLM.

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`). We tune some of the GBM parameters (number of trees, interaction depth and shrinkage) using a 5-fold cross validation approach [@hirempaper]. We list here the obtained results from the tuning strategy in the paper. We further fix the `bag.fraction` to 0.75 and the minimum number of observations for each node (`n.minobsinnode`) to 100.

```{r}
# Results of hierarchical model calibration
gbm_param_settle <- list('n.trees' = 225, 'interaction.depth' = 1, 'shrinkage' = 0.05)
gbm_param_pay    <- list('n.trees' = 125, 'interaction.depth' = 3, 'shrinkage' = 0.05)
gbm_param_size   <- list('n.trees' = 700, 'interaction.depth' = 1, 'shrinkage' = 0.05)

# Model specifications
model_gbm <- hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 9, open == 1)) %>%
  layer_gbm('settlement', distribution = 'bernoulli', bag.fraction = 0.75, n.minobsinnode = 100,
            n.trees = gbm_param_settle$n.trees, interaction.depth = gbm_param_settle$interaction.depth,
            shrinkage = gbm_param_settle$shrinkage, select_trees = 'last') %>%
  layer_gbm('payment', distribution = 'bernoulli', bag.fraction = 0.75, n.minobsinnode = 100,            
            n.trees = gbm_param_pay$n.trees, interaction.depth = gbm_param_pay$interaction.depth,
            shrinkage = gbm_param_pay$shrinkage, select_trees = 'last') %>%
  layer_gbm('size', distribution = 'gamma', bag.fraction = 0.75, n.minobsinnode = 100,
            n.trees = gbm_param_size$n.trees, interaction.depth = gbm_param_size$interaction.depth,
            shrinkage = gbm_param_size$shrinkage, select_trees = 'last',
            filter = function(data){data$payment == 1})
```

We now fit the hierarchical GBM on the observed portfolio of simulated claims.

```{r}
# Covariates
covariates_gbm <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'rep.delay', 'calendar.year')

# Fitting the hierarchical GBM
model_gbm <- hirem::fit(model_gbm,
                 weights = weight,
                 weight.var = 'dev.year',
                 balance.var = 'dev.year',
                 settlement = paste0('settlement ~ 1 + ', paste0(covariates_gbm, collapse = ' + ')),
                 payment = paste0('payment ~ 1 + ', paste0(c(covariates_gbm, 'settlement'), collapse = ' + ')),
                 size = paste0('size ~ 1 + ', paste0(c(covariates_gbm,'settlement'), collapse = ' + ')))
```

### Hierarchical XGB

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`).

To tune the hyperparameters, one can activate a cross-validation by setting the `nfolds` parameter to the desired integer in the `layer_xgb` function. Optionally, one can provide a `hyper_grid` parameter or use a predefined one. The hyperparameters performing the best will then be retained automatically. Alternatively, one can activate a Bayesian optimization approach as shown below:

```{r}
# Bounds specification for Bayesian optimization
bounds <- list(
  eta = c(0.05,1),
  max_depth = c(1L,6L)
)

# Model specifications
model_xgb <- hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 9, open == 1)) %>%
  layer_xgb('settlement', objective = 'binary:logistic',
            eval_metric = 'logloss',
            bayesOpt = T, bayesOpt_min = T, bayesOpt_iters_n = 1, bayesOpt_bounds = bounds,
            grow_policy = 'lossguide',
            nfolds = 5,
            verbose = F) %>%
  layer_xgb('payment', objective = 'binary:logistic',
            eval_metric = 'logloss',
            bayesOpt = T, bayesOpt_min = T, bayesOpt_iters_n = 1, bayesOpt_bounds = bounds,
            grow_policy = 'lossguide',
            nfolds = 5,
            verbose = F) %>%
  layer_xgb('size', objective = 'reg:gamma',
            eval_metric = 'gamma-deviance',
            bayesOpt = T, bayesOpt_min = T, bayesOpt_iters_n = 1, bayesOpt_bounds = bounds,
            grow_policy = 'lossguide',
            nfolds = 5,
            verbose = F,
            filter = function(data){data$payment == 1})
```

We now fit the hierarchical XGB on the observed portfolio of simulated claims.

```{r message=TRUE}
# Covariates
covariates_xgb <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'rep.delay', 'calendar.year')

# Fitting the hierarchical XGB
model_xgb <- hirem::fit(model_xgb,
                        weights = weight,
                        weight.var = 'dev.year',
                        balance.var = 'dev.year',
                        settlement = paste0('settlement ~ ', paste0(covariates_xgb, collapse = ' + ')) ,
                        payment = paste0('payment ~ ', paste0(c(covariates_xgb, 'settlement'), collapse = ' + ')),
                        size = paste0('size ~ ', paste0(c(covariates_xgb,'settlement'), collapse = ' + ')))
```

### Hierarchical MLP

We will use the gamma deviance as custom loss function and metric in `keras`:

```{r, message=FALSE}
gamma_deviance_keras <- function(yobs, yhat) {
  K <- backend()
  2*K$sum((yobs-yhat)/yhat - K$log(yobs/yhat))
}

metric_gamma_deviance_keras <- keras::custom_metric("gamma_deviance_keras", function(yobs, yhat) {
  gamma_deviance_keras(yobs, yhat)
})
```

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`). 

```{r message=FALSE, warning=FALSE}
# Model specifications
model_mlp <-  hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 9, open == 1)) %>%
  layer_mlp_keras('settlement', distribution = 'bernoulli',
                  step_log = F,
                  step_normalize = F,
                  loss = 'binary_crossentropy',
                  metrics = 'accuracy',
                  optimizer = optimizer_nadam(learning_rate = .01),
                  validation_split = 0,
                  hidden = c(20,15,10),
                  activation.output = 'sigmoid',
                  batch_normalization = F,
                  family_for_init = binomial(), # default link = logit
                  epochs = 100,
                  batch_size = 1000,
                  monitor = 'accuracy',
                  patience = 20) %>%
  layer_mlp_keras('payment', distribution = 'bernoulli',
                  step_log = F,
                  step_normalize = F,
                  loss = 'binary_crossentropy',
                  metrics = 'accuracy',
                  optimizer = optimizer_nadam(learning_rate = .01),
                  validation_split = 0,
                  hidden = c(20,15,10),
                  activation.output = 'sigmoid',
                  batch_normalization = F,
                  family_for_init = binomial(), # default link = logit
                  epochs = 100,
                  batch_size = 1000,
                  monitor = 'accuracy',
                  patience = 20) %>%
  layer_mlp_keras('size', distribution = 'gamma',
                  step_log = F,
                  step_normalize = F,
                  loss = gamma_deviance_keras,
                  metrics = metric_gamma_deviance_keras,
                  optimizer = optimizer_nadam(learning_rate = .01),
                  validation_split = 0,
                  hidden = c(50,45,40),
                  activation.output = 'exponential',
                  batch_normalization = F,
                  family_for_init = Gamma(link=log), # default link = inverse
                  epochs = 100,
                  batch_size = 1000,
                  monitor = 'gamma_deviance_keras',
                  patience = 20,
                  filter = function(data){data$payment == 1})
```

We now fit the hierarchical MLP on the observed portfolio of simulated claims.

```{r message=FALSE, warning=FALSE}
# Covariates
covariates_mlp <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'rep.delay', 'calendar.year')

# Fitting the hierarchical MLP
model_mlp <- hirem::fit(model_mlp,
                        settlement = paste0('settlement ~ ', paste0(covariates_mlp, collapse = ' + ')),
                        payment = paste0('payment ~ ', paste0(c(covariates_mlp, 'settlement'), collapse = ' + ')),
                        size = paste0('size ~ ', paste0(c(covariates_mlp,'settlement'), collapse = ' + ')))

```

### Hierarchical CANN

We first define the model specifications of each layer. We only train the reserving model on the claim updates that are still open at the beginning of each year and are observed on the evaluation date (`calendar.year <= 9`).

```{r message=FALSE, warning=FALSE}
# Model specifications
model_cann <-  hirem(reserving_data) %>%
  split_data(observed = function(df) df %>% filter(calendar.year <= 9, open == 1)) %>%
  layer_cann('settlement', distribution = 'bernoulli',
               family_for_glm = binomial(link=logit),
               loss = 'binary_crossentropy',
               metrics = 'binary_crossentropy',
               optimizer = optimizer_nadam(learning_rate = .01),
               validation_split = 0,
               hidden = c(20,15,10),
               activation.output = 'sigmoid',
               activation.output.cann = 'sigmoid',
               fixed.cann = TRUE,
               monitor = 'binary_crossentropy',
               patience = 20,
               epochs = 100,
               batch_size = 1000) %>%
  layer_cann('payment', distribution = 'bernoulli',
               family_for_glm = binomial(link=logit),
               loss = 'binary_crossentropy',
               metrics = 'binary_crossentropy',
               optimizer = optimizer_nadam(learning_rate = .01),
               validation_split = 0,
               hidden = c(20,15,10),
               activation.output = 'sigmoid',
               activation.output.cann = 'sigmoid',
               fixed.cann = TRUE,
               monitor = 'binary_crossentropy',
               patience = 20,
               epochs = 100,
               batch_size = 1000) %>%
  layer_cann('size', distribution = 'gamma',
               family_for_glm = Gamma(link=log),
               loss = gamma_deviance_keras,
               metrics = metric_gamma_deviance_keras,
               optimizer = optimizer_nadam(learning_rate = .01),
               validation_split = 0,
               hidden = c(20,15,10),
               activation.output = 'exponential',
               activation.output.cann = 'exponential',
               fixed.cann = TRUE,
               monitor = 'gamma_deviance_keras',
               patience = 20,
               epochs = 100,
               batch_size = 1000,
               filter = function(data){data$payment == 1})
```

We now fit the hierarchical CANN on the observed portfolio of simulated claims. Notice that `dev.year.fact` is removed from the list of covariates to prevent an issue in the calibration process (loss function is `nan`).

```{r}
# Covariates
#covariates_cann <- c('type', 'dev.year.fact', 'rep.month', 'rep.year.fact', 'rep.delay', 'calendar.year')
covariates_cann2 <- c('type', 'rep.year.fact', 'rep.month', 'rep.delay', 'calendar.year')

# Fitting the hierarchical CANN
model_cann <- hirem::fit(model_cann,
                 settlement = paste0('settlement ~ ', paste0(covariates_cann2, collapse = ' + ')),
                 payment = paste0('payment ~ ', paste0(c(covariates_cann2, 'settlement'), collapse = ' + ')),
                 size = paste0('size ~ ', paste0(c(covariates_cann2,'settlement'), collapse = ' + ')))
```

## Predicting the future development of claims in the hierarchical reserving models
In the next step, we predict the future development of claims. We do this by simulating 50 different paths for each open claim in the year of the evaluation date and by averaging the results afterwards. In this prediction strategy, the hierarchical structure of the reserving model is preserved and the development of claims are simulated in chronological order.

We define an update function applied to the data for the simulation of each subsequent development year. 

```{r}
# Update function
update <- function(data) {
  data$dev.year <- data$dev.year + 1
  data$dev.year.fact <- factor(data$dev.year, levels = 1:9)
  
  data$calendar.year <- data$calendar.year + 1
  
  data$monthDev12[data$dev.year > 3] <- 'dev.year > 3'
  data$devYearMonth <- factor(paste(data$dev.year, data$monthDev12, sep = '-'))
  
  data
}

model_glm <- register_updater(model_glm, update)
model_gbm <- register_updater(model_gbm, update)
model_xgb <- register_updater(model_xgb, update)
model_mlp <- register_updater(model_mlp, update)
model_cann <- register_updater(model_cann, update)
```

Next, we apply the actual simulation of the development of claims over time beyond the observation window of those claims that are still open at the evaluation date (calendar year 9). Moreover, we apply the balance correction as explained in @hirempaper.

```{r}
nsim <- 50 # Instead of 100 (original value), to avoid memory issues

simul_glm <- simulate(model_glm,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 9, settlement == 0)},
                      data = model_glm$data_observed %>% dplyr::filter(calendar.year == 9),
                      balance.correction = TRUE)

simul_gbm <- simulate(model_gbm,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 9, settlement == 0)},
                      data = model_gbm$data_observed %>% dplyr::filter(calendar.year == 9),
                      balance.correction = TRUE)

simul_xgb <- simulate(model_xgb,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 9, settlement == 0)},
                      data = model_xgb$data_observed %>% dplyr::filter(calendar.year == 9),
                      balance.correction = TRUE)

simul_mlp <- simulate(model_mlp,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 9, settlement == 0)},
                      data = model_mlp$data_observed %>% dplyr::filter(calendar.year == 9))

simul_cann <- simulate(model_cann,
                      nsim = nsim,
                      filter = function(data){dplyr::filter(data, dev.year <= 9, settlement == 0)},
                      data = model_cann$data_observed %>% dplyr::filter(calendar.year == 9))

```

## Chain-ladder model
For comparison, we apply the classical chain ladder model to predict the total number of open claims, the total number of payments and the total payment sizes outside the observation window.

We first construct the incremental run-off triangles for the number of open claims, the number of payments and the total payment sizes in each reporting year and development year since reporting in the observed portfolio. We know the number of open claims in the year following the evaluation date since we have information whether or not a claim settles in the year of settlement. 

```{r}
# Incremental run-off triangles
triangle_open    <- construct_triangle(data = observed_data %>% filter(open == 1), group.var1 = 'rep.year', 
                                       group.var2 = 'dev.year', value = 'open', cumulative = FALSE)
triangle_payment <- construct_triangle(data = observed_data, group.var1 = 'rep.year',
                                       group.var2 = 'dev.year', value = 'payment', cumulative = FALSE)
triangle_size    <- construct_triangle(data = observed_data, group.var1 = 'rep.year',
                                       group.var2 = 'dev.year', value = 'size', cumulative = FALSE)

# Number of open claims in the year following the evaluation date
settle.evalyear <- observed_data %>% 
  filter(open == 1, calendar.year == 9) %>%
  group_by(rep.year, dev.year) %>%
  summarise(settlement = sum(settlement))

# The number of open claims in the year after the evaluation date
triangle_open[row(triangle_open) + col(triangle_open) == 11] <- 
  (triangle_open[row(triangle_open) + col(triangle_open) == 10] - rev(settle.evalyear$settlement))[1:8]
```

We then apply (a special version of) the chain-ladder model on the incremental run-off triangle for the number of open claims. For the number of payments and the payment sizes, we use the classical chain ladder model applied on the cumulative run-off triangles.

```{r}
# Chain ladder predictions
cl_open <- chainLadder_open(triangle_open)
cl_pay  <- chainLadder(triangle_payment, is_cumulatif = FALSE)
cl_size <- chainLadder(triangle_size, is_cumulatif = FALSE)
```

## Evaluating the predictive performance of the chain-ladder model and the hierarchical GLM and GBM

First, we compare the prediction for the total number of open claims in the test set.

```{r}
nsim <- 50

# Predictions
obs_open_total <- prediction_data %>% filter(calendar.year != 10) %>% summarise(Total = sum(open)) %>% pull(Total)
cl_open_total  <- sum(cl_open)
glm_open_total <- simul_glm %>% filter(calendar.year != 10) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
gbm_open_total <- simul_gbm %>% filter(calendar.year != 10) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
xgb_open_total <- simul_xgb %>% filter(calendar.year != 10) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
mlp_open_total <- simul_mlp %>% filter(calendar.year != 10) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)
cann_open_total <- simul_cann %>% filter(calendar.year != 10) %>% summarise(Total = sum(open)/nsim) %>% pull(Total)

# Print Results
c('Actual' =  obs_open_total, 'Chain-Ladder' = cl_open_total, 'Hierarchical GLM' = glm_open_total, 'Hierarchical GBM' = gbm_open_total, 'Hierarchical XGB' = xgb_open_total, 'Hierarchical MLP' = mlp_open_total, 'Hierarchical CANN' = cann_open_total)
```

Second, we compare the prediction for the total number of payments in the prediction data set.

```{r}
# Predictions
obs_pay_total <- prediction_data %>% filter(calendar.year != 10) %>% summarise(Total = sum(payment)) %>% pull(Total)
cl_pay_total  <- sum(cl_pay)
glm_pay_total <- simul_glm %>% filter(calendar.year != 10) %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
gbm_pay_total <- simul_gbm %>% filter(calendar.year != 10) %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
xgb_pay_total <- simul_xgb %>% filter(calendar.year != 10) %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
mlp_pay_total <- simul_mlp %>% filter(calendar.year != 10) %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)
cann_pay_total <- simul_cann %>% filter(calendar.year != 10) %>% summarise(Total = sum(payment)/nsim) %>% pull(Total)

# Print Results
c('Actual' = obs_pay_total, 'Chain-Ladder' = cl_pay_total, 'Hierarchical GLM' = glm_pay_total, 'Hierarchical GBM' = gbm_pay_total, 'Hierarchical XGB' = xgb_pay_total, 'Hierarchical MLP' = mlp_pay_total, 'Hierarchical CANN' = cann_pay_total)
```

Third, we compare the prediction for the total number of payment sizes in the prediction set.

```{r}
# Predictions
obs_size_total <- prediction_data %>% filter(calendar.year != 10) %>% summarise(Total = sum(size)) %>% pull(Total)
cl_size_total  <- sum(cl_size)
glm_size_total <- simul_glm %>% filter(calendar.year != 10) %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
gbm_size_total <- simul_gbm %>% filter(calendar.year != 10) %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
xgb_size_total <- simul_xgb %>% filter(calendar.year != 10) %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
mlp_size_total <- simul_mlp %>% filter(calendar.year != 10) %>% summarise(Total = sum(size)/nsim) %>% pull(Total)
cann_size_total <- simul_cann %>% filter(calendar.year != 10) %>% summarise(Total = sum(size)/nsim) %>% pull(Total)

# Print Results
c('Actual' = obs_size_total, 'Chain-Ladder' = cl_size_total, 'Hierarchical GLM' = glm_size_total, 'Hierarchical GBM' = gbm_size_total, 'Hierarchical XGB' = xgb_size_total, 'Hierarchical MLP' = mlp_size_total, 'Hierarchical CANN' = cann_size_total)
```

## References

<div id="refs"></div>
